{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/dlabdata1/lugeon/datasets/websites_dmoz_multi.gz', compression='gzip')[['url', 'lang', 'lang_id', 'cat0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(572098, 4)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en = df[df.lang_id == 'en']\n",
    "df_en.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_en.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Business      148144\n",
       "Society        82079\n",
       "Arts           66721\n",
       "Shopping       54062\n",
       "Recreation     46095\n",
       "Computers      45194\n",
       "Sports         34890\n",
       "Science        28138\n",
       "Health         24218\n",
       "Reference      21663\n",
       "Games          10246\n",
       "Home            6952\n",
       "News            3696\n",
       "Name: cat0, dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en.cat0.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_url(url):\n",
    "    url = re.sub(r\"www.|http://|https://|-|_\", '', url)\n",
    "    return url.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-116-650908217de8>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_en['clean_url'] = df_en.url.apply(clean_url)\n"
     ]
    }
   ],
   "source": [
    "df_en['clean_url'] = df_en.url.apply(clean_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>lang</th>\n",
       "      <th>lang_id</th>\n",
       "      <th>cat0</th>\n",
       "      <th>clean_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>www.232analyzer.com</td>\n",
       "      <td>English</td>\n",
       "      <td>en</td>\n",
       "      <td>Computers</td>\n",
       "      <td>232analyzer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.cs-interiors.co.uk</td>\n",
       "      <td>English</td>\n",
       "      <td>en</td>\n",
       "      <td>Business</td>\n",
       "      <td>csinteriors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ccc-stl.org</td>\n",
       "      <td>English</td>\n",
       "      <td>en</td>\n",
       "      <td>Society</td>\n",
       "      <td>cccstl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>www.utahwebdesign.com</td>\n",
       "      <td>English</td>\n",
       "      <td>en</td>\n",
       "      <td>Computers</td>\n",
       "      <td>utahwebdesign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>www.hampsteadstage.org</td>\n",
       "      <td>English</td>\n",
       "      <td>en</td>\n",
       "      <td>Arts</td>\n",
       "      <td>hampsteadstage</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      url     lang lang_id       cat0       clean_url\n",
       "0     www.232analyzer.com  English      en  Computers     232analyzer\n",
       "1  www.cs-interiors.co.uk  English      en   Business     csinteriors\n",
       "2             ccc-stl.org  English      en    Society          cccstl\n",
       "3   www.utahwebdesign.com  English      en  Computers   utahwebdesign\n",
       "4  www.hampsteadstage.org  English      en       Arts  hampsteadstage"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ngram(s, n):\n",
    "    return [s[i:i+n] for i in range(0, len(s)-n+1)]\n",
    "\n",
    "def concat_ngrams(s, ns):\n",
    "    l = []\n",
    "    for n in ns:\n",
    "        l += compute_ngram(s, n)\n",
    "    return ' '.join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-119-9f27cb45cc67>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_en['ngrams'] = df_en.apply(lambda row: concat_ngrams(row.clean_url, ns), axis=1)\n"
     ]
    }
   ],
   "source": [
    "ns = range(3, 6) # from 3 to 5\n",
    "df_en['ngrams'] = df_en.apply(lambda row: concat_ngrams(row.clean_url, ns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>lang</th>\n",
       "      <th>lang_id</th>\n",
       "      <th>cat0</th>\n",
       "      <th>clean_url</th>\n",
       "      <th>ngrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>www.232analyzer.com</td>\n",
       "      <td>English</td>\n",
       "      <td>en</td>\n",
       "      <td>Computers</td>\n",
       "      <td>232analyzer</td>\n",
       "      <td>232 32a 2an ana nal aly lyz yze zer 232a 32an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.cs-interiors.co.uk</td>\n",
       "      <td>English</td>\n",
       "      <td>en</td>\n",
       "      <td>Business</td>\n",
       "      <td>csinteriors</td>\n",
       "      <td>csi sin int nte ter eri rio ior ors csin sint ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ccc-stl.org</td>\n",
       "      <td>English</td>\n",
       "      <td>en</td>\n",
       "      <td>Society</td>\n",
       "      <td>cccstl</td>\n",
       "      <td>ccc ccs cst stl cccs ccst cstl cccst ccstl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>www.utahwebdesign.com</td>\n",
       "      <td>English</td>\n",
       "      <td>en</td>\n",
       "      <td>Computers</td>\n",
       "      <td>utahwebdesign</td>\n",
       "      <td>uta tah ahw hwe web ebd bde des esi sig ign ut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>www.hampsteadstage.org</td>\n",
       "      <td>English</td>\n",
       "      <td>en</td>\n",
       "      <td>Arts</td>\n",
       "      <td>hampsteadstage</td>\n",
       "      <td>ham amp mps pst ste tea ead ads dst sta tag ag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      url     lang lang_id       cat0       clean_url  \\\n",
       "0     www.232analyzer.com  English      en  Computers     232analyzer   \n",
       "1  www.cs-interiors.co.uk  English      en   Business     csinteriors   \n",
       "2             ccc-stl.org  English      en    Society          cccstl   \n",
       "3   www.utahwebdesign.com  English      en  Computers   utahwebdesign   \n",
       "4  www.hampsteadstage.org  English      en       Arts  hampsteadstage   \n",
       "\n",
       "                                              ngrams  \n",
       "0  232 32a 2an ana nal aly lyz yze zer 232a 32an ...  \n",
       "1  csi sin int nte ter eri rio ior ors csin sint ...  \n",
       "2         ccc ccs cst stl cccs ccst cstl cccst ccstl  \n",
       "3  uta tah ahw hwe web ebd bde des esi sig ign ut...  \n",
       "4  ham amp mps pst ste tea ead ads dst sta tag ag...  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_en.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.rand(df_en.shape[0])\n",
    "mask = r < 0.9\n",
    "train = df_en[mask]\n",
    "test = df_en[~mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "n_features = 20_000\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=n_features)\n",
    "x_train = vectorizer.fit_transform(train.ngrams.values)\n",
    "x_test = vectorizer.transform(test.ngrams.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "encoder.fit(df_en.cat0.unique())\n",
    "\n",
    "y_train = encoder.transform(train.cat0.values)\n",
    "y_test = encoder.transform(test.cat0.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      59903\n",
       "1     132866\n",
       "2      40635\n",
       "3       9239\n",
       "4      21735\n",
       "5       6265\n",
       "6       3300\n",
       "7      41460\n",
       "8      19440\n",
       "9      25270\n",
       "10     48535\n",
       "11     73955\n",
       "12     31277\n",
       "dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_counts = pd.Series(y_train).value_counts().sort_index()\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25623338, 0.11552352, 0.37773221, 1.66134304, 0.706195  ,\n",
       "       2.44998378, 4.65125709, 0.37021583, 0.78956525, 0.60740595,\n",
       "       0.31624907, 0.20754714, 0.49074874])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = class_counts.values / class_counts.values.sum()\n",
    "weights = 1 / weights\n",
    "weights = weights / weights.sum()\n",
    "weights = weights * 13\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Embnet, self).__init__()\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(n_features, 768)\n",
    "        self.fc2 = torch.nn.Linear(768, 768)\n",
    "        self.fc2 = torch.nn.Linear(768, 768)\n",
    "        self.fc3 = torch.nn.Linear(768, 13)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(F.relu(x))\n",
    "        x = self.fc3(F.relu(x))\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target):\n",
    "    nb_samples = output.shape[0]\n",
    "    \n",
    "    # Convert probability to decision\n",
    "    output_class = torch.argmax(output, 1)\n",
    "    \n",
    "    nb_correct = (output_class == target).sum().item()\n",
    "    return nb_correct / nb_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = torch.FloatTensor(x_train.toarray())\n",
    "train_target = torch.LongTensor(y_train)\n",
    "test_input = torch.FloatTensor(x_test.toarray())\n",
    "test_target = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([513880, 20000]), torch.Size([513880]))"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input.shape, train_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 15961357\n",
      "Epoch 0 | Train loss : 1.651 | Test loss : 1.789 | Train accuracy : 0.403 | Test accuracy : 0.374\n",
      "Epoch 1 | Train loss : 1.504 | Test loss : 1.767 | Train accuracy : 0.428 | Test accuracy : 0.387\n",
      "Epoch 2 | Train loss : 1.416 | Test loss : 1.791 | Train accuracy : 0.443 | Test accuracy : 0.390\n",
      "Epoch 3 | Train loss : 1.352 | Test loss : 1.834 | Train accuracy : 0.454 | Test accuracy : 0.393\n",
      "Epoch 4 | Train loss : 1.301 | Test loss : 1.887 | Train accuracy : 0.463 | Test accuracy : 0.394\n",
      "Epoch 5 | Train loss : 1.257 | Test loss : 1.948 | Train accuracy : 0.472 | Test accuracy : 0.396\n",
      "Epoch 6 | Train loss : 1.217 | Test loss : 2.015 | Train accuracy : 0.481 | Test accuracy : 0.397\n",
      "Epoch 7 | Train loss : 1.179 | Test loss : 2.091 | Train accuracy : 0.490 | Test accuracy : 0.398\n",
      "Epoch 8 | Train loss : 1.140 | Test loss : 2.176 | Train accuracy : 0.500 | Test accuracy : 0.399\n",
      "Epoch 9 | Train loss : 1.101 | Test loss : 2.273 | Train accuracy : 0.510 | Test accuracy : 0.403\n",
      "Epoch 10 | Train loss : 1.060 | Test loss : 2.378 | Train accuracy : 0.521 | Test accuracy : 0.404\n",
      "Epoch 11 | Train loss : 1.018 | Test loss : 2.491 | Train accuracy : 0.534 | Test accuracy : 0.408\n",
      "Epoch 12 | Train loss : 0.975 | Test loss : 2.613 | Train accuracy : 0.548 | Test accuracy : 0.410\n",
      "Epoch 13 | Train loss : 0.931 | Test loss : 2.738 | Train accuracy : 0.563 | Test accuracy : 0.413\n",
      "Epoch 14 | Train loss : 0.885 | Test loss : 2.869 | Train accuracy : 0.579 | Test accuracy : 0.414\n",
      "Epoch 15 | Train loss : 0.838 | Test loss : 3.001 | Train accuracy : 0.598 | Test accuracy : 0.416\n",
      "Epoch 16 | Train loss : 0.789 | Test loss : 3.135 | Train accuracy : 0.617 | Test accuracy : 0.418\n"
     ]
    }
   ],
   "source": [
    "torch.set_num_threads(12)\n",
    "\n",
    "epochs = 70\n",
    "batch_size = 256\n",
    "\n",
    "model = Embnet()\n",
    "nb_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: {}\".format(nb_trainable_params))\n",
    "# Loss\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(weights))\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), 1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, eps=1e-8, patience=3, verbose=True)\n",
    "\n",
    "#model.train(True)\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    for input, target in zip(train_input.split(batch_size), train_target.split(batch_size)):\n",
    "                             \n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        #model.train(False)\n",
    "        train_output = model(train_input)\n",
    "        test_output = model(test_input)\n",
    "        train_loss = criterion(train_output, train_target)\n",
    "        train_acc = accuracy(train_output, train_target)\n",
    "        test_loss = criterion(test_output, test_target)\n",
    "        test_acc = accuracy(test_output, test_target)\n",
    "        print(\"Epoch {}\".format(e) +\\\n",
    "              \" | Train loss : {:.3f}\".format(train_loss) +\\\n",
    "              \" | Test loss : {:.3f}\".format(test_loss) +\\\n",
    "              \" | Train accuracy : {:.3f}\".format(train_acc) +\\\n",
    "              \" | Test accuracy : {:.3f}\".format(test_acc))\n",
    "        \n",
    "    scheduler.step(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:basic-env] *",
   "language": "python",
   "name": "conda-env-basic-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

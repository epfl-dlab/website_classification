{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:1\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(12) # only with CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/dlabdata1/lugeon/dmozfinalset/dmoz_en_full_train_finalemb.gz', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('/dlabdata1/lugeon/dmozfinalset/dmoz_en_full_valid_finalemb.gz', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>embedding</th>\n",
       "      <th>error</th>\n",
       "      <th>cat0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunrise.mobileread.com</td>\n",
       "      <td>[0.04443914070725441, 0.006837127730250359, 0....</td>\n",
       "      <td>ucdk:oo__</td>\n",
       "      <td>Computers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>firefalcon.blogspot.com</td>\n",
       "      <td>[-0.0012733626645058393, 0.08161848783493042, ...</td>\n",
       "      <td>ucdk:oo__</td>\n",
       "      <td>Computers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>www.sarcophagus.co.uk</td>\n",
       "      <td>[0.09634807705879211, -0.18308357894420624, 0....</td>\n",
       "      <td>ucdk:oooo</td>\n",
       "      <td>Computers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>www.mjmcom.co.uk</td>\n",
       "      <td>[-0.0032559819519519806, 0.009568585082888603,...</td>\n",
       "      <td>ucdk:ooo_</td>\n",
       "      <td>Computers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>joyofandroid.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>invalid website</td>\n",
       "      <td>Computers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       url                                          embedding  \\\n",
       "0   sunrise.mobileread.com  [0.04443914070725441, 0.006837127730250359, 0....   \n",
       "1  firefalcon.blogspot.com  [-0.0012733626645058393, 0.08161848783493042, ...   \n",
       "2    www.sarcophagus.co.uk  [0.09634807705879211, -0.18308357894420624, 0....   \n",
       "3         www.mjmcom.co.uk  [-0.0032559819519519806, 0.009568585082888603,...   \n",
       "4         joyofandroid.com                                                NaN   \n",
       "\n",
       "             error       cat0  \n",
       "0        ucdk:oo__  Computers  \n",
       "1        ucdk:oo__  Computers  \n",
       "2        ucdk:oooo  Computers  \n",
       "3        ucdk:ooo_  Computers  \n",
       "4  invalid website  Computers  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ucdk:oo__          31186\n",
       "invalid website    21316\n",
       "ucdk:ooo_          21243\n",
       "ucdk:oooo          18085\n",
       "ucdk:oo_o           1486\n",
       "ucdk:o___           1137\n",
       "ucdk:o_o_            173\n",
       "ucdk:o_oo             17\n",
       "ucdk:o__o              4\n",
       "ucdk:____              1\n",
       "Name: error, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.error.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ucdk:oo__          8684\n",
       "invalid website    5868\n",
       "ucdk:ooo_          5678\n",
       "ucdk:oooo          4905\n",
       "ucdk:oo_o           526\n",
       "ucdk:o___           292\n",
       "ucdk:o_o_            43\n",
       "ucdk:o__o             2\n",
       "ucdk:o_oo             2\n",
       "Name: error, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.error.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid(error):\n",
    "    return not(error in ['invalid website', 'ucdk:____', 'ucdk:o___', 'ucdk:o_oo', 'ucdk:o_o_', 'ucdk:o__o'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid = train_data[train_data.error.apply(is_valid)]\n",
    "test_valid = test_data[test_data.error.apply(is_valid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 0.76% of valid embeddings\n"
     ]
    }
   ],
   "source": [
    "print(\"There is {:.2f}% of valid embeddings\".format(train_valid.shape[0] / train_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72000, 19793)"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_valid.shape[0], test_valid.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Science       6240\n",
       "Computers     6204\n",
       "Games         6174\n",
       "Recreation    6172\n",
       "Shopping      6093\n",
       "Sports        6037\n",
       "Business      6035\n",
       "Arts          6035\n",
       "Society       6033\n",
       "Reference     6025\n",
       "Health        5917\n",
       "Home          3714\n",
       "News          1321\n",
       "Name: cat0, dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_valid.cat0.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Games         1552\n",
       "Science       1549\n",
       "Computers     1547\n",
       "Recreation    1540\n",
       "News          1536\n",
       "Business      1530\n",
       "Home          1530\n",
       "Arts          1529\n",
       "Reference     1521\n",
       "Shopping      1518\n",
       "Society       1505\n",
       "Sports        1471\n",
       "Health        1465\n",
       "Name: cat0, dtype: int64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_valid.cat0.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-201-254580315fef>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_valid['embedding'] = train_valid.apply(lambda row: np.array(ast.literal_eval(row.embedding)), axis=1)\n",
      "<ipython-input-201-254580315fef>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_valid['embedding'] = test_valid.apply(lambda row: np.array(ast.literal_eval(row.embedding)), axis=1)\n"
     ]
    }
   ],
   "source": [
    "train_valid['embedding'] = train_valid.apply(lambda row: np.array(ast.literal_eval(row.embedding)), axis=1)\n",
    "test_valid['embedding'] = test_valid.apply(lambda row: np.array(ast.literal_eval(row.embedding)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "_test_inputs = np.concatenate(test_valid.embedding.to_numpy()).reshape(test_valid.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train_inputs = np.concatenate(train_valid.embedding.to_numpy()).reshape(train_valid.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = np.sort(train_valid.cat0.unique()).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are numpy series\n",
    "_train_targets = train_valid.cat0.apply(categories.index)\n",
    "_test_targets = test_valid.cat0.apply(categories.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "idx = np.arange(_train_inputs.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "_train_inputs = _train_inputs[idx]\n",
    "_train_targets = _train_targets.iloc[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64704     7\n",
       "19928    11\n",
       "49236     8\n",
       "64142    10\n",
       "80937    12\n",
       "         ..\n",
       "48986     8\n",
       "8094      1\n",
       "72170    12\n",
       "1104      2\n",
       "20703    11\n",
       "Name: cat0, Length: 72000, dtype: int64"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.FloatTensor(_train_inputs).to(device)\n",
    "test_inputs = torch.FloatTensor(_test_inputs).to(device)\n",
    "train_targets = torch.LongTensor(_train_targets.values).to(device)\n",
    "test_targets = torch.LongTensor(_test_targets.values).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([72000, 3072]),\n",
       " torch.Size([72000]),\n",
       " torch.Size([19793, 3072]),\n",
       " torch.Size([19793]))"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.shape, train_targets.shape, test_inputs.shape, test_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Webnet(nn.Module):\n",
    "    def __init__(self, features_dim, out_dim, internal_dim):\n",
    "        super(Webnet, self).__init__()\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(features_dim, internal_dim)\n",
    "        self.fc2 = torch.nn.Linear(internal_dim, internal_dim)\n",
    "        self.fc3 = torch.nn.Linear(internal_dim, internal_dim)\n",
    "        self.fc4 = torch.nn.Linear(internal_dim, out_dim)\n",
    "        \n",
    "        self.drop = torch.nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(F.relu(x))\n",
    "        x = self.drop(x)\n",
    "        x = self.fc3(F.relu(x))\n",
    "        x = self.drop(x)\n",
    "        x = self.fc4(F.relu(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DME(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent_dim, embeddings_dim):\n",
    "        \"\"\"\n",
    "        the dimensions of the prior embeddings must be passed has a list\n",
    "        \"\"\"\n",
    "        super(DME, self).__init__()\n",
    "        \n",
    "        self.n_embeddings = len(embeddings_dim) # number of prior embeddings\n",
    "        self.transforms = nn.ModuleList([torch.nn.Linear(dim, latent_dim).to(device) for dim in embeddings_dim]) # linear transformation into the latent space\n",
    "        self.attention = torch.nn.Linear(latent_dim, 1) # linear transformation defining the attention\n",
    "        self.softmax = nn.Softmax(dim=1) # to normalize the attention \n",
    "        \n",
    "    def forward(self, embeddings):\n",
    "        \"\"\"\n",
    "        The embeddings are given as tuples of the form [samples x embedding_dim]\n",
    "        \"\"\"\n",
    "        \n",
    "        # first we transform each prior embedding into the latent space\n",
    "        latent_embeddings = [transform(x) for transform, x in zip(self.transforms, embeddings)] # this is a list\n",
    "        \n",
    "        # then we apply the attention transformation to each of the latent embeddings\n",
    "        att = torch.cat([self.attention(x) for x in latent_embeddings], dim=1) # this is a tensor\n",
    "        \n",
    "        # we normalize the attention and reshape for multiplication\n",
    "        att_coeffs = self.softmax(att).reshape(-1, 1, self.n_embeddings)\n",
    "        \n",
    "        # we reshape for multiplication\n",
    "        latent_embeddings_t = torch.cat(latent_embeddings, dim=1).reshape(-1, self.n_embeddings, latent_dim)\n",
    "        \n",
    "        # the reshape is so that we multiply matrices of the form \n",
    "        # [#samples x 1 x #embeddings] @ [#samples x #embeddings x latent_dim]\n",
    "        \n",
    "        aggregation = att_coeffs.matmul(latent_embeddings_t)\n",
    "        \n",
    "        \n",
    "        return aggregation.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self, latent_dim, out_dim, internal_dim, embeddings_dim):\n",
    "        super(DynamicClassifier, self).__init__()\n",
    "        \n",
    "        self.dme = DME(latent_dim, embeddings_dim)\n",
    "        self.classifier = Webnet(latent_dim, out_dim, internal_dim)\n",
    "        self.embeddings_dim = embeddings_dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        splitted_embeddings = x.split(self.embeddings_dim, dim=1)\n",
    "        latent_embedding = self.dme(splitted_embeddings)\n",
    "        output = self.classifier(latent_embedding)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7602, 0.7602, 0.7395, 0.7431, 0.7754, 1.2353, 3.4730, 0.7433, 0.7615,\n",
       "        0.7352, 0.7530, 0.7605, 0.7600])"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = _train_targets.value_counts().sort_index().values\n",
    "\n",
    "weights = torch.Tensor([1 / (x / sum(counts)) for x in counts])\n",
    "weights = weights / weights.sum() * counts.shape[0]\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 1106413\n",
      "Epoch 0 | Train loss : 1.362 | Test loss : 1.259 | Train accuracy : 0.576 | Test accuracy : 0.577\n",
      "Epoch 1 | Train loss : 1.263 | Test loss : 1.234 | Train accuracy : 0.609 | Test accuracy : 0.599\n",
      "Epoch 2 | Train loss : 1.222 | Test loss : 1.216 | Train accuracy : 0.625 | Test accuracy : 0.608\n",
      "Epoch 3 | Train loss : 1.171 | Test loss : 1.159 | Train accuracy : 0.637 | Test accuracy : 0.618\n",
      "Epoch 4 | Train loss : 1.139 | Test loss : 1.187 | Train accuracy : 0.644 | Test accuracy : 0.613\n",
      "Epoch 5 | Train loss : 1.114 | Test loss : 1.222 | Train accuracy : 0.655 | Test accuracy : 0.623\n",
      "Epoch 6 | Train loss : 1.101 | Test loss : 1.198 | Train accuracy : 0.660 | Test accuracy : 0.626\n",
      "Epoch 7 | Train loss : 1.067 | Test loss : 1.172 | Train accuracy : 0.670 | Test accuracy : 0.630\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-370-42067fb353ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/lugeon/dl-env/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/lugeon/dl-env/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feature_dim = 768\n",
    "latent_dim = 500\n",
    "internal_dim = 300\n",
    "out_dim = len(categories)\n",
    "\n",
    "splits = [768, 768, 768, 768]\n",
    "\n",
    "\n",
    "nb_epochs = 100\n",
    "batch_size = 64\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#model = DynamicClassifier(latent_dim, out_dim, internal_dim, splits, binary).to(device)\n",
    "model = Webnet(4 * feature_dim, out_dim, internal_dim).to(device)\n",
    "        \n",
    "nb_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(\"Number of parameters: {}\".format(nb_trainable_params))\n",
    " \n",
    "criterion = nn.CrossEntropyLoss(weight=weights.to(device))\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), 1e-3)\n",
    "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=int(nb_epochs / 2), gamma=0.1)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=10, verbose=True)\n",
    "\n",
    "train_acc_hist = []\n",
    "train_loss_hist = []\n",
    "test_acc_hist = []\n",
    "test_loss_hist = []\n",
    "\n",
    "\n",
    "for e in range(nb_epochs):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for input, target in zip(train_inputs.split(batch_size), train_targets.split(batch_size)):\n",
    "                  \n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        train_outputs = model(train_inputs)\n",
    "        test_outputs = model(test_inputs)\n",
    "        \n",
    "        train_loss = criterion(train_outputs, train_targets)\n",
    "        test_loss = criterion(test_outputs, test_targets)\n",
    "\n",
    "        _, train_preds = torch.max(train_outputs, 1)\n",
    "        _, test_preds = torch.max(test_outputs, 1)\n",
    "        \n",
    "        train_acc = torch.sum(train_preds == train_targets.data).item() / train_targets.shape[0]\n",
    "        test_acc = torch.sum(test_preds == test_targets.data).item() / test_targets.shape[0]\n",
    "         \n",
    "        print(\"Epoch {}\".format(e) +\\\n",
    "              \" | Train loss : {:.3f}\".format(train_loss) +\\\n",
    "              \" | Test loss : {:.3f}\".format(test_loss) +\\\n",
    "              \" | Train accuracy : {:.3f}\".format(train_acc) +\\\n",
    "              \" | Test accuracy : {:.3f}\".format(test_acc))\n",
    "        \n",
    "        \n",
    "    scheduler.step(test_acc)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:basic-env] *",
   "language": "python",
   "name": "conda-env-basic-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

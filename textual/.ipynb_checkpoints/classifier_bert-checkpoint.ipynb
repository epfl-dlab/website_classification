{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/dlabdata1/lugeon/'\n",
    "name = 'websites_alexa_10000_5cat_emb_bert'\n",
    "ext = '.gz'\n",
    "data = pd.read_csv(folder + name + ext, names = ['last_id', 'uid', 'emb', 'cat0'], header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.emb.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['emb'] = data.apply(lambda row: np.array(ast.literal_eval(row.emb)), axis=1)\n",
    "data['emb_red'] = data.emb.apply(lambda x: np.delete(x, 227))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>last_id</th>\n",
       "      <th>uid</th>\n",
       "      <th>emb</th>\n",
       "      <th>cat0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>36126</td>\n",
       "      <td>[-0.5465862154960632, -0.4531528055667877, 0.5...</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>25238</td>\n",
       "      <td>[-0.5333141684532166, -0.25329938530921936, 0....</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20371</td>\n",
       "      <td>[-0.5620501637458801, -0.5124451518058777, 0.8...</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11312</td>\n",
       "      <td>[-0.6283508539199829, -0.11153016984462738, 0....</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>16434</td>\n",
       "      <td>[-0.062120892107486725, -0.3814326822757721, 0...</td>\n",
       "      <td>Arts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   last_id    uid                                                emb  cat0\n",
       "0        0  36126  [-0.5465862154960632, -0.4531528055667877, 0.5...  Arts\n",
       "1        1  25238  [-0.5333141684532166, -0.25329938530921936, 0....  Arts\n",
       "2        2  20371  [-0.5620501637458801, -0.5124451518058777, 0.8...  Arts\n",
       "3        3  11312  [-0.6283508539199829, -0.11153016984462738, 0....  Arts\n",
       "4        4  16434  [-0.062120892107486725, -0.3814326822757721, 0...  Arts"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38533, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Arts         7835\n",
       "Computers    7820\n",
       "Science      7642\n",
       "Health       7630\n",
       "Sports       7606\n",
       "Name: cat0, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.cat0.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize(s):\n",
    "    if s == 'Health':\n",
    "        return 0\n",
    "    if s == 'Science':\n",
    "        return 1\n",
    "    if s == 'Arts':\n",
    "        return 2\n",
    "    if s == 'Computers':\n",
    "        return 3\n",
    "    if s == 'Sports':\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cat_no'] = data.apply(lambda row: categorize(row.cat0), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.concatenate(data.emb.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 768\n",
    "input = torch.tensor(embeddings)\n",
    "input = torch.reshape(input, (-1, embedding_dim)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "input_norm = torch.FloatTensor(normalize(input, axis=0)) # normalizing w.r.t to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([38533, 768])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_no = data.cat_no.values\n",
    "target = torch.tensor(cat_no).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([38533])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = np.arange(emb_norm.shape[0])\n",
    "np.random.shuffle(id)\n",
    "\n",
    "tr_id = id[:32_000]\n",
    "te_id = id[32_000:]\n",
    "\n",
    "train_input_ = input_norm[tr_id]\n",
    "test_input_ = input_norm[te_id]\n",
    "\n",
    "train_target_ = target[tr_id]\n",
    "test_target_ = target[te_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Arts         6537\n",
       "Computers    6477\n",
       "Science      6367\n",
       "Health       6323\n",
       "Sports       6296\n",
       "Name: cat0, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[tr_id].cat0.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(768, 200)\n",
    "        self.fc2 = nn.Linear(200, 200)\n",
    "        self.fc3 = nn.Linear(200, 200)\n",
    "        self.fc4 = nn.Linear(200, 5)\n",
    "        self.drop = nn.Dropout(0.6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(F.relu(x))\n",
    "        x = self.drop(x)\n",
    "        x = self.fc3(F.relu(x))\n",
    "        x = self.drop(x)\n",
    "        x = self.fc4(F.relu(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target):\n",
    "    nb_samples = output.shape[0]\n",
    "    \n",
    "    # Convert probability to decision\n",
    "    output_class = torch.argmax(output, 1)\n",
    "    \n",
    "    nb_correct = (output_class == target).sum().item()\n",
    "    return nb_correct / nb_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train loss : 1.604 | Train accuracy : 0.213 | Test accuracy : 0.208\n",
      "Epoch 1 | Train loss : 1.337 | Train accuracy : 0.398 | Test accuracy : 0.399\n",
      "Epoch 2 | Train loss : 1.269 | Train accuracy : 0.447 | Test accuracy : 0.446\n",
      "Epoch 3 | Train loss : 1.215 | Train accuracy : 0.495 | Test accuracy : 0.496\n",
      "Epoch 4 | Train loss : 1.136 | Train accuracy : 0.555 | Test accuracy : 0.561\n",
      "Epoch 5 | Train loss : 1.051 | Train accuracy : 0.594 | Test accuracy : 0.600\n",
      "Epoch 6 | Train loss : 1.000 | Train accuracy : 0.614 | Test accuracy : 0.616\n",
      "Epoch 7 | Train loss : 0.961 | Train accuracy : 0.636 | Test accuracy : 0.637\n",
      "Epoch 8 | Train loss : 0.930 | Train accuracy : 0.652 | Test accuracy : 0.649\n",
      "Epoch 9 | Train loss : 0.905 | Train accuracy : 0.667 | Test accuracy : 0.663\n",
      "Epoch 10 | Train loss : 0.880 | Train accuracy : 0.681 | Test accuracy : 0.678\n",
      "Epoch 11 | Train loss : 0.856 | Train accuracy : 0.697 | Test accuracy : 0.689\n",
      "Epoch 12 | Train loss : 0.835 | Train accuracy : 0.707 | Test accuracy : 0.699\n",
      "Epoch 13 | Train loss : 0.815 | Train accuracy : 0.715 | Test accuracy : 0.706\n",
      "Epoch 14 | Train loss : 0.800 | Train accuracy : 0.722 | Test accuracy : 0.712\n",
      "Epoch 15 | Train loss : 0.783 | Train accuracy : 0.729 | Test accuracy : 0.721\n",
      "Epoch 16 | Train loss : 0.767 | Train accuracy : 0.735 | Test accuracy : 0.725\n",
      "Epoch 17 | Train loss : 0.754 | Train accuracy : 0.739 | Test accuracy : 0.730\n",
      "Epoch 18 | Train loss : 0.742 | Train accuracy : 0.743 | Test accuracy : 0.737\n",
      "Epoch 19 | Train loss : 0.735 | Train accuracy : 0.745 | Test accuracy : 0.737\n",
      "Epoch 20 | Train loss : 0.728 | Train accuracy : 0.748 | Test accuracy : 0.742\n",
      "Epoch 21 | Train loss : 0.715 | Train accuracy : 0.753 | Test accuracy : 0.744\n",
      "Epoch 22 | Train loss : 0.709 | Train accuracy : 0.755 | Test accuracy : 0.750\n",
      "Epoch 23 | Train loss : 0.708 | Train accuracy : 0.756 | Test accuracy : 0.748\n",
      "Epoch 24 | Train loss : 0.695 | Train accuracy : 0.762 | Test accuracy : 0.752\n",
      "Epoch 25 | Train loss : 0.693 | Train accuracy : 0.760 | Test accuracy : 0.752\n",
      "Epoch 26 | Train loss : 0.685 | Train accuracy : 0.763 | Test accuracy : 0.755\n",
      "Epoch 27 | Train loss : 0.684 | Train accuracy : 0.763 | Test accuracy : 0.755\n",
      "Epoch 28 | Train loss : 0.677 | Train accuracy : 0.765 | Test accuracy : 0.757\n",
      "Epoch 29 | Train loss : 0.671 | Train accuracy : 0.769 | Test accuracy : 0.757\n",
      "Epoch 30 | Train loss : 0.667 | Train accuracy : 0.770 | Test accuracy : 0.760\n",
      "Epoch 31 | Train loss : 0.663 | Train accuracy : 0.770 | Test accuracy : 0.760\n",
      "Epoch 32 | Train loss : 0.660 | Train accuracy : 0.772 | Test accuracy : 0.762\n",
      "Epoch 33 | Train loss : 0.660 | Train accuracy : 0.771 | Test accuracy : 0.760\n",
      "Epoch 34 | Train loss : 0.654 | Train accuracy : 0.774 | Test accuracy : 0.761\n",
      "Epoch 35 | Train loss : 0.653 | Train accuracy : 0.774 | Test accuracy : 0.761\n",
      "Epoch 36 | Train loss : 0.646 | Train accuracy : 0.777 | Test accuracy : 0.764\n",
      "Epoch 37 | Train loss : 0.644 | Train accuracy : 0.778 | Test accuracy : 0.765\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "batch_size = 64\n",
    "\n",
    "model = Classifier()\n",
    "\n",
    "# Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), 1e-4)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size= int(epochs/2), gamma = 0.1)\n",
    "\n",
    "# Training the model\n",
    "model.train(True)\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    for input, target in zip(train_input_.split(batch_size), train_target_.split(batch_size)):\n",
    "                             \n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    model.train(False)\n",
    "    tr_output = model(train_input_)\n",
    "    te_output = model(test_input_)\n",
    "    tr_loss = criterion(tr_output, train_target_)\n",
    "    tr_acc = accuracy(tr_output, train_target_)\n",
    "    te_acc = accuracy(te_output, test_target_)\n",
    "    model.train(True)\n",
    "    print(\"Epoch {}\".format(e) +\\\n",
    "          \" | Train loss : {:.3f}\".format(tr_loss) +\\\n",
    "          \" | Train accuracy : {:.3f}\".format(tr_acc) +\\\n",
    "          \" | Test accuracy : {:.3f}\".format(te_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
